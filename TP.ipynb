{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7i98HvId9tT",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score, recall_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn import metrics\n",
    "\n",
    "import graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from io import StringIO\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractClassificationProblem:\n",
    "    labels = ['No Fraude', 'Fraude']\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Comienza Entrenamiento\")\n",
    "        self.print_self()\n",
    "        self.clf_model.fit(self.X_train, self.y_train)\n",
    "        self.y_predict = self.clf_model.predict(self.X_test)\n",
    "        print(\"Entrenado\")\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        self.print_self()\n",
    "        ConfusionMatrixDisplay.from_estimator(estimator=self.clf_model,\n",
    "                                              X=self.X_test, \n",
    "                                              y=self.y_test,\n",
    "                                              display_labels=self.labels)\n",
    "        plt.show()\n",
    "    \n",
    "    def show_classification_report(self):\n",
    "        self.print_self()\n",
    "        print(classification_report(self.y_test, self.y_predict, target_names=self.labels))\n",
    "\n",
    "    def accuracy(self):\n",
    "        return accuracy_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def recall(self):\n",
    "        return recall_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def precision_score(self):\n",
    "        return precision_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def print_self(self):\n",
    "        pass\n",
    "    \n",
    "    def auc(self):\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, self.y_predict)\n",
    "        return auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    def roc_curve(self):\n",
    "        y_pred_proba = self.clf_model.predict_proba(self.X_test)[::,1]\n",
    "        fpr, tpr, _ = metrics.roc_curve(self.y_test,  y_pred_proba)\n",
    "        auc = metrics.roc_auc_score(self.y_test, y_pred_proba)\n",
    "        plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "        plt.legend(loc=4)\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class AbstractDecisionTree(AbstractClassificationProblem):\n",
    "    criterion = \"\"\n",
    "    tipo = \"\"\n",
    "    \n",
    "    def __init__(self, dataset, X, X_train, X_test, y_train, y_test, target, max_depth=None, min_samples_leaf=1):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.clf_model = DecisionTreeClassifier(criterion=self.criterion, \n",
    "                                                random_state=42,\n",
    "                                                max_depth=max_depth,\n",
    "                                                min_samples_leaf=min_samples_leaf,\n",
    "                                                max_features=None,\n",
    "                                                max_leaf_nodes=None,\n",
    "                                                splitter='best')\n",
    "\n",
    "        self.target = list(dataset['isFraud'].unique())\n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "    \n",
    "    def show_matrix(self):\n",
    "        dot_data = tree.export_graphviz(self.clf_model,\n",
    "                                        out_file=None,\n",
    "                                        feature_names=self.feature_names,\n",
    "                                        class_names=str(self.target),\n",
    "                                        filled=True,\n",
    "                                        rounded=True,\n",
    "                                        special_characters=True)\n",
    "        dot_data = StringIO()\n",
    "        export_graphviz(self.clf_model, \n",
    "                        out_file=dot_data, \n",
    "                        filled=True, \n",
    "                        rounded=True, \n",
    "                        special_characters=True,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=self.labels)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "        return Image(graph.create_png())\n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Arbol de decision - \" + self.tipo, \"**\")\n",
    "        print('**', \"max_depth=\" + str(self.max_depth) + \",\", \"min_samples_leaf=\" + str(self.min_samples_leaf), \"**\")\n",
    "\n",
    "\n",
    "class GiniDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"gini\"\n",
    "    tipo = \"Gini Index\"\n",
    "\n",
    "class InformationGainDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"entropy\"\n",
    "    tipo = \"Information Gain\"\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "class AbstractNeuralNetwork(AbstractClassificationProblem):\n",
    "    solver = ''\n",
    "    tipo = ''\n",
    "    \n",
    "    def __init__(self, X, y, X_train, X_test, y_train, y_test, alpha=1e-5, hidden_layer_sizes=(15,), max_iter=5000):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        self.X_train = self._scale(X_train)\n",
    "        self.X_test = self._scale(X_test)\n",
    "        \n",
    "        #https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "        self.y_train = y_train.values.ravel()\n",
    "\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.clf_model = MLPClassifier(solver=self.solver,\n",
    "                                       alpha=alpha, \n",
    "                                       hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                       random_state=42, \n",
    "                                       max_iter=max_iter)   \n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Red Neuronal - \" + self.tipo, \"**\")\n",
    "        print(\"**\", \n",
    "              \"alpha=\" + str(self.alpha), \n",
    "              \"hidden_layer_sizes=\" + str(self.hidden_layer_sizes), \n",
    "              \"max_iter=\" + str(self.max_iter), \n",
    "              \"**\")\n",
    "\n",
    "    def _scale(self, X):\n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        return scaler.transform(X)\n",
    "\n",
    "\n",
    "class LBFGSNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'lbfgs'\n",
    "    tipo = \"LBFGS\"\n",
    "\n",
    "class SGDNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'sgd'\n",
    "    tipo = \"SGD\"\n",
    "\n",
    "class AdamNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'adam'\n",
    "    tipo = 'ADAM'\n",
    "\n",
    "class Comparator:\n",
    "    models = []\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        for model in self.models:\n",
    "            model.show_confusion_matrix()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def show_classification_report(self):\n",
    "        for model in self.models:\n",
    "            model.show_classification_report()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def accuracy(self):\n",
    "        for model in self.models:\n",
    "            print(model.accuracy())\n",
    "    \n",
    "    def recall(self):\n",
    "        for model in self.models:\n",
    "            print(model.recall())\n",
    "    \n",
    "    def precision_score(self):\n",
    "        for model in self.models:\n",
    "            print(model.precision_score())\n",
    "    \n",
    "    def auc(self):\n",
    "        for model in self.models:\n",
    "            print(model.auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterTuning():\n",
    "    \n",
    "    def __init__(self, dataset, decisionTreeCriterion, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.decisionTreeCriterion = decisionTreeCriterion\n",
    "        \n",
    "    def train(self, parameters_to_tune_array, parameter_name):\n",
    "        def get_dec_tree_class(random_state=42, max_depth=None, min_samples_leaf=1, max_features=None, max_leaf_nodes=None, min_samples_split=2):\n",
    "            return DecisionTreeClassifier(criterion=self.decisionTreeCriterion, \n",
    "                                        random_state=random_state,\n",
    "                                        max_depth=max_depth,\n",
    "                                        min_samples_leaf=min_samples_leaf,\n",
    "                                        max_features=max_features,\n",
    "                                        max_leaf_nodes=max_leaf_nodes,\n",
    "                                        min_samples_split=min_samples_split,\n",
    "                                        splitter='best')\n",
    "            \n",
    "        train_results = []\n",
    "        test_results = []\n",
    "        max_depth=None\n",
    "        min_samples_split=2\n",
    "        min_samples_leaf=None\n",
    "        for curr_parameter in parameters_to_tune_array:\n",
    "            if parameter_name == 'max_depth':\n",
    "                max_depth = curr_parameter\n",
    "            elif parameter_name == 'min_samples_split':\n",
    "                min_samples_split = curr_parameter\n",
    "            elif parameter_name == 'min_samples_leaf':\n",
    "                min_samples_leaf = curr_parameter\n",
    "                \n",
    "            dt = get_dec_tree_class(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "            dt.fit(self.X_train, self.y_train)\n",
    "            train_pred = dt.predict(self.X_train)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_train, train_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous train results\n",
    "            train_results.append(roc_auc)\n",
    "            \n",
    "            y_pred = dt.predict(self.X_test)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, y_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous test results\n",
    "            test_results.append(roc_auc)\n",
    "            \n",
    "        line1, = plt.plot(parameters_to_tune_array, train_results, 'b', label='Train AUC')\n",
    "        line2, = plt.plot(parameters_to_tune_array, test_results, 'r', label='Test AUC')\n",
    "        plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "        plt.ylabel('AUC score')\n",
    "        plt.xlabel('Tree depth')\n",
    "        plt.show()\n",
    "    \n",
    "    def get_best_max_depth(self, hasta):\n",
    "        max_depths = np.linspace(1, hasta, hasta, dtype=\"int\", endpoint=True)\n",
    "        print(max_depths)\n",
    "        self.train(max_depths, 'max_depth')\n",
    "        \n",
    "    def get_best_min_samples_split(self):\n",
    "        min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "        print(min_samples_splits)\n",
    "        self.train(min_samples_splits, 'min_samples_split')\n",
    "        \n",
    "    def get_best_min_samples_leaf(self):\n",
    "        min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "        print(min_samples_leafs)\n",
    "        self.train(min_samples_leafs, 'min_samples_leaf')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ANALISIS DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levantamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Fraud.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadisticas descriptivas de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se borran las columnas 'nameOrig' y 'nameDest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Revisamos si hay valores perdidos (None, NaN) en el resto del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos contra la variable 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()[\"isFraud\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset (Normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de tipos de transacciones que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transacciones fraudulentas y no fraudulentas diferenciadas por su tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.countplot(x=\"type\", data=df, hue=\"isFraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentajes de transacciones fraudulentas de cada tipo de transaccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "df_type_fraud = pd.DataFrame(dict(Counter(df['type'])).items(), columns=['type', 'IsFraud'])\n",
    "\n",
    "pie_porcentaje_transacciones_fraudulentas = px.pie(df_type_fraud, values=\"IsFraud\", names='type', title='Transacciones Fraudulentas', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "pie_porcentaje_transacciones_fraudulentas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeo el type a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_type = {'CASH_IN': 0,'CASH_OUT': 1,'PAYMENT': 2,'TRANSFER': 3,'DEBIT': 4}\n",
    "df['type_numeric'] = df.type.map(mapping_type)\n",
    "df.drop('type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('isFraud',axis=1)\n",
    "y = df[['isFraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Primeras pruebas con datos desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Separación de los datos de entrenamiento (80%) y datos para testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entreno el Arbol de Decision (Gini Impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline = GiniDecisionTree(dataset=df,\n",
    "                          X=X,\n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'])\n",
    "dtGini_baseline.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Medidas de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Entreno el Arbol de Decision (Information Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline = InformationGainDecisionTree(dataset=df,\n",
    "                                         X=X, \n",
    "                                         X_train=X_train, \n",
    "                                         X_test=X_test, \n",
    "                                         y_train=y_train, \n",
    "                                         y_test=y_test, \n",
    "                                         target=df['isFraud'])\n",
    "dtInfoGain_baseline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hice una prueba agregando \"dummies\" en lugar de fijar un número para cada valor de \"type\", pero al parecer el resultado es el mismo.\n",
    "#df2 = pd.read_csv(\"./Fraud.csv\")\n",
    "#df2.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n",
    "# Getting Dummies from all other categorical vars\n",
    "#for col in df2.dtypes[df2.dtypes == 'object'].index:\n",
    "#    for_dummy = df2.pop(col)\n",
    "#    df2 = pd.concat([df2, pd.get_dummies(for_dummy, prefix=col)], axis=1)\n",
    "#X2 = df2.drop('isFraud',axis=1)\n",
    "#y2 = df2[['isFraud']]\n",
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "#dtInfoGain2 = InformationGainDecisionTree(df2, X=X2, \n",
    "#                                         X_train=X2_train, \n",
    "#                                         X_test=X2_test, \n",
    "#                                         y_train=y2_train, \n",
    "#                                         y_test=y2_test, \n",
    "#                                         target=df2['isFraud'],\n",
    "#                                         max_depth=5, \n",
    "#                                         min_samples_leaf=5)\n",
    "#dtInfoGain2.train()\n",
    "#dtInfoGain2.show_confusion_matrix()\n",
    "#dtInfoGain2.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparo parámetros para max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            dataset=df,\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "parameterTuning_InfoGain.get_best_max_depth(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            dataset=df,\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            dataset=df,\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entreno Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrego un Comparador de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini = GiniDecisionTree(df,\n",
    "                          X=X, \n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'],\n",
    "                          max_depth=5, \n",
    "                          min_samples_leaf=5)\n",
    "dtGini.train()\n",
    "\n",
    "dtInfoGain = InformationGainDecisionTree(df,\n",
    "                                         X=X, \n",
    "                                         X_train=X_train, \n",
    "                                         X_test=X_test, \n",
    "                                         y_train=y_train, \n",
    "                                         y_test=y_test, \n",
    "                                         target=df['isFraud'],\n",
    "                                         max_depth=5, \n",
    "                                         min_samples_leaf=5)\n",
    "dtInfoGain.train()\n",
    "\n",
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtGini, dtInfoGain, nn\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeras pruebas con datos Balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_balanced, y_balanced = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced_train, X_balanced_test, y_balanced_train, y_balanced_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced = GiniDecisionTree(X=X, \n",
    "                                  y=y, \n",
    "                                  X_train=X_balanced_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_balanced_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  max_depth=5,\n",
    "                                  min_samples_leaf=5)\n",
    "dtGiniBalanced.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
