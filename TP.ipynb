{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7i98HvId9tT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "from sklearn import metrics\n",
    "\n",
    "import graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from io import StringIO\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractClassificationProblem:\n",
    "    labels = ['No Fraude', 'Fraude']\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Comienza Entrenamiento\")\n",
    "        self.print_self()\n",
    "        self.clf_model.fit(self.X_train, self.y_train)\n",
    "        self.y_predict = self.clf_model.predict(self.X_test)\n",
    "        print(\"Entrenado\")\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        self.print_self()\n",
    "        ConfusionMatrixDisplay.from_estimator(estimator=self.clf_model,\n",
    "                                              X=self.X_test, \n",
    "                                              y=self.y_test,\n",
    "                                              display_labels=self.labels)\n",
    "        plt.show()\n",
    "    \n",
    "    def show_classification_report(self):\n",
    "        self.print_self()\n",
    "        print(classification_report(self.y_test, self.y_predict, target_names=self.labels))\n",
    "\n",
    "    def accuracy(self):\n",
    "        return accuracy_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def recall(self):\n",
    "        return recall_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def precision_score(self):\n",
    "        return precision_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def f1_score(self):\n",
    "        return f1_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def print_self(self):\n",
    "        pass\n",
    "    \n",
    "    def auc(self):\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, self.y_predict)\n",
    "        return auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    def roc_curve(self):        \n",
    "        fpr, tpr, thresholds = roc_curve(self.y_test, self.y_predict, pos_label=1)\n",
    "        auc = metrics.roc_auc_score(self.y_test, self.y_predict)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(fpr, tpr)\n",
    "        ax.plot([0, 1], [0, 1], color='navy', linestyle='--', label='random')\n",
    "        plt.title(f'AUC: {auc}')\n",
    "        ax.set_xlabel('False positive rate')\n",
    "        ax.set_ylabel('True positive rate')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class AbstractDecisionTree(AbstractClassificationProblem):\n",
    "    criterion = \"\"\n",
    "    tipo = \"\"\n",
    "    \n",
    "    def __init__(self, dataset, X, X_train, X_test, y_train, y_test, target, max_depth=None, min_samples_leaf=1):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.clf_model = DecisionTreeClassifier(criterion=self.criterion, \n",
    "                                                random_state=42,\n",
    "                                                max_depth=max_depth,\n",
    "                                                min_samples_leaf=min_samples_leaf,\n",
    "                                                max_features=None,\n",
    "                                                max_leaf_nodes=None,\n",
    "                                                class_weight=None,\n",
    "                                                splitter='best')\n",
    "\n",
    "        self.target = list(dataset['isFraud'].unique())\n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "    \n",
    "    def show_matrix(self):\n",
    "        dot_data = tree.export_graphviz(self.clf_model,\n",
    "                                        out_file=None,\n",
    "                                        feature_names=self.feature_names,\n",
    "                                        class_names=str(self.target),\n",
    "                                        filled=True,\n",
    "                                        rounded=True,\n",
    "                                        special_characters=True)\n",
    "        dot_data = StringIO()\n",
    "        export_graphviz(self.clf_model, \n",
    "                        out_file=dot_data, \n",
    "                        filled=True, \n",
    "                        rounded=True, \n",
    "                        special_characters=True,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=self.labels)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "        return Image(graph.create_png())\n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Arbol de decision - \" + self.tipo, \"**\")\n",
    "        print('**', \"max_depth=\" + str(self.max_depth) + \",\", \"min_samples_leaf=\" + str(self.min_samples_leaf), \"**\")\n",
    "\n",
    "\n",
    "class GiniDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"gini\"\n",
    "    tipo = \"Gini Index\"\n",
    "\n",
    "class InformationGainDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"entropy\"\n",
    "    tipo = \"Information Gain\"\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "class AbstractNeuralNetwork(AbstractClassificationProblem):\n",
    "    solver = ''\n",
    "    tipo = ''\n",
    "    \n",
    "    def __init__(self, X, y, X_train, X_test, y_train, y_test, alpha=1e-5, hidden_layer_sizes=(15,), max_iter=5000):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        self.X_train = self._scale(X_train)\n",
    "        self.X_test = self._scale(X_test)\n",
    "        \n",
    "        #https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "        self.y_train = y_train.values.ravel()\n",
    "\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.clf_model = MLPClassifier(solver=self.solver,\n",
    "                                       alpha=alpha, \n",
    "                                       hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                       random_state=42, \n",
    "                                       max_iter=max_iter)   \n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Red Neuronal - \" + self.tipo, \"**\")\n",
    "        print(\"**\", \n",
    "              \"alpha=\" + str(self.alpha), \n",
    "              \"hidden_layer_sizes=\" + str(self.hidden_layer_sizes), \n",
    "              \"max_iter=\" + str(self.max_iter), \n",
    "              \"**\")\n",
    "\n",
    "    def _scale(self, X):\n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        return scaler.transform(X)\n",
    "\n",
    "\n",
    "class LBFGSNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'lbfgs'\n",
    "    tipo = \"LBFGS\"\n",
    "\n",
    "class SGDNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'sgd'\n",
    "    tipo = \"SGD\"\n",
    "\n",
    "class AdamNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'adam'\n",
    "    tipo = 'ADAM'\n",
    "\n",
    "class Comparator:\n",
    "    models = []\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        for model in self.models:\n",
    "            model.show_confusion_matrix()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def show_classification_report(self):\n",
    "        for model in self.models:\n",
    "            model.show_classification_report()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def accuracy(self):\n",
    "        for model in self.models:\n",
    "            print(model.accuracy())\n",
    "    \n",
    "    def recall(self):\n",
    "        for model in self.models:\n",
    "            print(model.recall())\n",
    "    \n",
    "    def precision_score(self):\n",
    "        for model in self.models:\n",
    "            print(model.precision_score())\n",
    "            \n",
    "    def f1_score(self):\n",
    "        for model in self.models:\n",
    "            print(model.f1_score())\n",
    "    \n",
    "    def auc(self):\n",
    "        for model in self.models:\n",
    "            print(model.auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterTuning():\n",
    "    \n",
    "    def __init__(self, decisionTreeCriterion, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.decisionTreeCriterion = decisionTreeCriterion\n",
    "        \n",
    "    def train(self, parameters_to_tune_array, parameter_name):\n",
    "        def get_dec_tree_class(random_state=42, max_depth=None, min_samples_leaf=1, max_features=None, max_leaf_nodes=None, min_samples_split=2, min_weight_fraction_leaf=0):\n",
    "            return DecisionTreeClassifier(criterion=self.decisionTreeCriterion, \n",
    "                                        random_state=random_state,\n",
    "                                        max_depth=max_depth,\n",
    "                                        min_samples_leaf=min_samples_leaf,\n",
    "                                        max_features=max_features,\n",
    "                                        max_leaf_nodes=max_leaf_nodes,\n",
    "                                        min_samples_split=min_samples_split,\n",
    "                                        class_weight=None,\n",
    "                                        min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                                        splitter='best')\n",
    "            \n",
    "        print(\"parameters tuning for {}:{}\".format(parameter_name, parameters_to_tune_array))\n",
    "        train_results = []\n",
    "        test_results = []\n",
    "        max_depth=None\n",
    "        min_samples_split=2\n",
    "        min_samples_leaf=None\n",
    "        for curr_parameter in parameters_to_tune_array:\n",
    "            if parameter_name == 'max_depth':\n",
    "                max_depth = curr_parameter\n",
    "            elif parameter_name == 'min_samples_split':\n",
    "                min_samples_split = curr_parameter\n",
    "            elif parameter_name == 'min_samples_leaf':\n",
    "                min_samples_leaf = curr_parameter\n",
    "                \n",
    "            dt = get_dec_tree_class(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "            dt.fit(self.X_train, self.y_train)\n",
    "            train_pred = dt.predict(self.X_train)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_train, train_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous train results\n",
    "            train_results.append(roc_auc)\n",
    "            \n",
    "            y_pred = dt.predict(self.X_test)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, y_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous test results\n",
    "            test_results.append(roc_auc)\n",
    "            \n",
    "        line1, = plt.plot(parameters_to_tune_array, train_results, 'b', label='Train AUC')\n",
    "        line2, = plt.plot(parameters_to_tune_array, test_results, 'r', label='Test AUC')\n",
    "        plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "        plt.ylabel('AUC score')\n",
    "        plt.xlabel(parameter_name)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_best_max_depth(self, hasta):\n",
    "        max_depths = np.linspace(1, hasta, hasta, dtype=\"int\", endpoint=True)\n",
    "        self.train(max_depths, 'max_depth')\n",
    "        \n",
    "    def get_best_min_samples_split(self):\n",
    "        min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "        self.train(min_samples_splits, 'min_samples_split')\n",
    "        \n",
    "    def get_best_min_samples_leaf(self):\n",
    "        min_samples_leafs = np.linspace(0.001, 0.005, 5, endpoint=True)\n",
    "        self.train(min_samples_leafs, 'min_samples_leaf')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANALISIS DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levantamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Fraud.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadisticas descriptivas de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se borran las columnas 'nameOrig' y 'nameDest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Revisamos si hay valores perdidos (None, NaN) en el resto del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos contra la variable 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()[\"isFraud\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset (Normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de tipos de transacciones que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transacciones fraudulentas y no fraudulentas diferenciadas por su tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.countplot(x=\"type\", data=df, hue=\"isFraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentajes de transacciones fraudulentas de cada tipo de transaccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "df_type_fraud = pd.DataFrame(dict(Counter(df['type'])).items(), columns=['type', 'IsFraud'])\n",
    "\n",
    "pie_porcentaje_transacciones_fraudulentas = px.pie(df_type_fraud, values=\"IsFraud\", names='type', title='Transacciones Fraudulentas', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "pie_porcentaje_transacciones_fraudulentas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeo el type a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_type = {'CASH_IN': 0,'CASH_OUT': 1,'PAYMENT': 2,'TRANSFER': 3,'DEBIT': 4}\n",
    "df['type_numeric'] = df.type.map(mapping_type)\n",
    "df.drop('type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('isFraud',axis=1)\n",
    "y = df[['isFraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Primeras pruebas con datos desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Separación de los datos de entrenamiento (80%) y datos para testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entreno el Arbol de Decision (Gini Impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline = GiniDecisionTree(dataset=df,\n",
    "                          X=X,\n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'])\n",
    "dtGini_baseline.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Medidas de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Entreno el Arbol de Decision (Information Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline = InformationGainDecisionTree(dataset=df,\n",
    "                                                  X=X,\n",
    "                                                  X_train=X_train, \n",
    "                                                  X_test=X_test, \n",
    "                                                  y_train=y_train,\n",
    "                                                  y_test=y_test, \n",
    "                                                  target=df['isFraud'])\n",
    "dtInfoGain_baseline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hice una prueba agregando \"dummies\" en lugar de fijar un número para cada valor de \"type\", pero al parecer el resultado es el mismo.\n",
    "#df2 = pd.read_csv(\"./Fraud.csv\")\n",
    "#df2.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n",
    "# Getting Dummies from all other categorical vars\n",
    "#for col in df2.dtypes[df2.dtypes == 'object'].index:\n",
    "#    for_dummy = df2.pop(col)\n",
    "#    df2 = pd.concat([df2, pd.get_dummies(for_dummy, prefix=col)], axis=1)\n",
    "#X2 = df2.drop('isFraud',axis=1)\n",
    "#y2 = df2[['isFraud']]\n",
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "#dtInfoGain2 = InformationGainDecisionTree(df2, X=X2, \n",
    "#                                         X_train=X2_train, \n",
    "#                                         X_test=X2_test, \n",
    "#                                         y_train=y2_train, \n",
    "#                                         y_test=y2_test, \n",
    "#                                         target=df2['isFraud'],\n",
    "#                                         max_depth=5, \n",
    "#                                         min_samples_leaf=5)\n",
    "#dtInfoGain2.train()\n",
    "#dtInfoGain2.show_confusion_matrix()\n",
    "#dtInfoGain2.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparo parámetros para max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "parameterTuning_InfoGain.get_best_max_depth(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entreno Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Agrego un Comparador de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini = GiniDecisionTree(df,\n",
    "                          X=X, \n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'],\n",
    "                          max_depth=5, \n",
    "                          min_samples_leaf=5)\n",
    "dtGini.train()\n",
    "\n",
    "dtInfoGain = InformationGainDecisionTree(df,\n",
    "                                         X=X, \n",
    "                                         X_train=X_train, \n",
    "                                         X_test=X_test, \n",
    "                                         y_train=y_train, \n",
    "                                         y_test=y_test, \n",
    "                                         target=df['isFraud'],\n",
    "                                         max_depth=5, \n",
    "                                         min_samples_leaf=5)\n",
    "dtInfoGain.train()\n",
    "\n",
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtGini, dtInfoGain, nn\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Primeras pruebas con datos Balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes and plot\n",
    "target_count = df[\"isFraud\"].value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "target_count.plot(kind='bar', title='Count (isFraud)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "target_0_count, target_1_count=df[\"isFraud\"].value_counts()\n",
    "# Seperate classes\n",
    "target_0 = df[df[\"isFraud\"] == 0]\n",
    "target_1 = df[df[\"isFraud\"] == 1]\n",
    "\n",
    "# Resample target1 to match target 0 count\n",
    "target_0_undersample = target_0.sample(target_1_count)\n",
    "# Merge back to single df\n",
    "test_undersample = pd.concat([target_0_undersample, target_1], axis=0)\n",
    "# Show counts and plot\n",
    "print('Random under-sampling:')\n",
    "test_undersample[\"isFraud\"].value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersample = test_undersample.drop('isFraud',axis=1)\n",
    "y_undersample = test_undersample[['isFraud']]\n",
    "X_undersample_train, X_undersample_test, y_undersample_train, y_undersample_test = train_test_split(X_undersample, y_undersample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_undersample = GiniDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_undersample_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_undersample_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'],\n",
    "                                      max_depth=5,\n",
    "                                      min_samples_leaf=5)\n",
    "dtGini_undersample.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_undersample.show_classification_report()\n",
    "dtGini_undersample.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "target_0_count, target_1_count = df[\"isFraud\"].value_counts()\n",
    "# Seperate classes\n",
    "target_0 = df[df[\"isFraud\"] == 0]\n",
    "target_1 = df[df[\"isFraud\"] == 1]\n",
    "\n",
    "# Resample target0 to match target 1 count\n",
    "target_1_oversample = target_1.sample(target_0_count, replace=True)\n",
    "# Merge back to single df\n",
    "test_oversample = pd.concat([target_1_oversample, target_0], axis=0)\n",
    "# Show counts and plot\n",
    "print('Random over-sampling:')\n",
    "print(test_oversample[\"isFraud\"].value_counts())\n",
    "test_oversample[\"isFraud\"].value_counts().plot(kind='bar', title='Count (isFraud)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversample = test_oversample.drop('isFraud',axis=1)\n",
    "y_oversample = test_oversample[['isFraud']]\n",
    "X_oversample_train, X_oversample_test, y_oversample_train, y_oversample_test = train_test_split(X_oversample, y_oversample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_oversample = GiniDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_oversample_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_oversample_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'],\n",
    "                                      max_depth=5,\n",
    "                                      min_samples_leaf=5)\n",
    "dtGini_oversample.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_oversample.show_classification_report()\n",
    "dtGini_oversample.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_balanced, y_balanced = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced_train, X_balanced_test, y_balanced_train, y_balanced_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced = GiniDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_balanced_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_balanced_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  max_depth=5,\n",
    "                                  min_samples_leaf=5)\n",
    "dtGiniBalanced.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGiniBalanced.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "#Setting the range for class weights\n",
    "weights = np.linspace(0.0,0.99,2)\n",
    "\n",
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= lr, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          verbose=2).fit(X_train, y_train)\n",
    "\n",
    "#Ploting the score for different values of weight\n",
    "sns.set_style('whitegrid')\n",
    "plt.figure(figsize=(12,8))\n",
    "weigh_data = pd.DataFrame({ 'score': gridsearch.cv_results_['mean_test_score'], 'weight': (1- weights)})\n",
    "sns.lineplot(weigh_data['weight'], weigh_data['score'])\n",
    "plt.xlabel('Weight for class 1')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xticks([round(i/10,1) for i in range(0,11,1)])\n",
    "plt.title('Scoring for different class weights', fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Clasificador usando xgboost\n",
    "clf1 = xgb.XGBClassifier()\n",
    "  \n",
    "# Establezca el rango de búsqueda de los parámetros de xgboost para buscar, búsqueda de valores para los 6 parámetros principales de XGBoost\n",
    "param_dist = {\n",
    "        #'n_estimators':range(80,200,4),\n",
    "        'max_depth':range(2,15,1),\n",
    "        #'learning_rate':np.linspace(0.01,2,20),\n",
    "        #'subsample':np.linspace(0.7,0.9,20),\n",
    "        #'colsample_bytree':np.linspace(0.5,0.98,10),\n",
    "        'min_child_weight':range(1,9,1)\n",
    "        }\n",
    "\n",
    "grid = RandomizedSearchCV(clf1,param_dist,cv = 3,scoring = 'neg_log_loss',n_iter=1,n_jobs = -1)\n",
    "\n",
    "#Entrenamiento en el set de entrenamiento\n",
    "grid.fit(df.values,np.ravel(df[\"isFraud\"].values))\n",
    "#Vuelve con el mejor entrenador\n",
    "best_estimator = grid.best_estimator_\n",
    "print(best_estimator)\n",
    "#Output la precisión del entrenador óptimo\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparo parámetros para datos Balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_balanced_train,\n",
    "                                            X_test=X_balanced_test,\n",
    "                                            y_train=y_balanced_train,\n",
    "                                            y_test=y_balanced_test)\n",
    "\n",
    "parameterTuning_InfoGain.get_best_max_depth(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_balanced_train,\n",
    "                                            X_test=X_balanced_test,\n",
    "                                            y_train=y_balanced_train,\n",
    "                                            y_test=y_balanced_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_balanced_train,\n",
    "                                            X_test=X_balanced_test,\n",
    "                                            y_train=y_balanced_train,\n",
    "                                            y_test=y_balanced_test)\n",
    "parameterTuning_InfoGain.get_best_min_samples_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
