{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7i98HvId9tT",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score, recall_score, precision_score, f1_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "import graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from io import StringIO\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import time\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractClassificationProblem:\n",
    "    labels = ['No Fraude', 'Fraude']\n",
    "    desc = \"\"\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Comienza Entrenamiento\")\n",
    "        inicio = time.time()\n",
    "        self.print_self()\n",
    "        self.clf_model.fit(self.X_train, self.y_train)\n",
    "        self.y_predict = self.clf_model.predict(self.X_test)\n",
    "        print(\"Entrenado\")       \n",
    "        fin = time.time()\n",
    "        print(\"Tiempo total (min): {}\".format(round((fin-inicio)/60, 2)))\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        self.print_self()\n",
    "        ConfusionMatrixDisplay.from_estimator(estimator=self.clf_model,\n",
    "                                              X=self.X_test, \n",
    "                                              y=self.y_test,\n",
    "                                              display_labels=self.labels)\n",
    "        plt.show()\n",
    "    \n",
    "    def show_classification_report(self):\n",
    "        self.print_self()\n",
    "        print(classification_report(self.y_test, self.y_predict, target_names=self.labels))\n",
    "\n",
    "    def accuracy(self):\n",
    "        return accuracy_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def recall(self):\n",
    "        return recall_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def precision_score(self):\n",
    "        return precision_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def f1_score(self):\n",
    "        return f1_score(self.y_test, self.y_predict)\n",
    "    \n",
    "    def print_self(self):\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf_model.predict_proba(x)\n",
    "    \n",
    "    def auc(self):\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, self.y_predict)\n",
    "        return auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    def roc_curve(self):\n",
    "        fpr, tpr, thresholds = roc_curve(self.y_test, self.y_predict, pos_label=1)\n",
    "        auc = metrics.roc_auc_score(self.y_test, self.y_predict)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(fpr,tpr,label=\"[\"+self.tipo+\"] - AUC=\"+str(auc))\n",
    "        ax.plot([0, 1], [0, 1], color='navy', linestyle='--', label='random')\n",
    "        plt.title(f'Curva ROC')\n",
    "        ax.set_xlabel('False positive rate')\n",
    "        ax.set_ylabel('True positive rate')\n",
    "        ax.legend() \n",
    "\n",
    "class AbstractDecisionTree(AbstractClassificationProblem):\n",
    "    criterion = \"\"\n",
    "    tipo = \"\"\n",
    "    \n",
    "    def __init__(self, dataset, X, X_train, X_test, y_train, y_test, target, max_depth=None, min_samples_leaf=1, min_samples_split=2, desc=\"\"):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.clf_model = DecisionTreeClassifier(criterion=self.criterion, \n",
    "                                                random_state=42,\n",
    "                                                max_depth=max_depth,\n",
    "                                                min_samples_leaf=min_samples_leaf,\n",
    "                                                min_samples_split=min_samples_split,\n",
    "                                                max_features=None,\n",
    "                                                max_leaf_nodes=None,\n",
    "                                                class_weight=None,\n",
    "                                                splitter='best')\n",
    "        self.desc = desc\n",
    "\n",
    "        self.target = list(dataset['isFraud'].unique())\n",
    "        self.feature_names = list(X.columns)\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def show_matrix(self):\n",
    "        dot_data = tree.export_graphviz(self.clf_model,\n",
    "                                        out_file=None,\n",
    "                                        feature_names=self.feature_names,\n",
    "                                        class_names=str(self.target),\n",
    "                                        filled=True,\n",
    "                                        rounded=True,\n",
    "                                        special_characters=True)\n",
    "        dot_data = StringIO()\n",
    "        export_graphviz(self.clf_model, \n",
    "                        out_file=dot_data, \n",
    "                        filled=True, \n",
    "                        rounded=True, \n",
    "                        special_characters=True,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=self.labels)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "        return Image(graph.create_png())\n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Arbol de decision - \" + self.tipo + \" - \" + self.desc, \"**\")\n",
    "        print('**', \"max_depth=\" + str(self.max_depth) + \",\", \"min_samples_leaf=\" + str(self.min_samples_leaf), \"min_samples_split=\" + str(self.min_samples_split), \"**\")\n",
    "\n",
    "\n",
    "class GiniDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"gini\"\n",
    "    tipo = \"Gini Index\"\n",
    "\n",
    "class InformationGainDecisionTree(AbstractDecisionTree):\n",
    "    criterion = \"entropy\"\n",
    "    tipo = \"Information Gain\"\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "class AbstractNeuralNetwork(AbstractClassificationProblem):\n",
    "    solver = ''\n",
    "    tipo = ''\n",
    "    \n",
    "    def __init__(self, X, y, X_train, X_test, y_train, y_test, alpha=1e-5, hidden_layer_sizes=(15,), max_iter=5000, desc=\"\"):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        self.X_train = self._scale(X_train)\n",
    "        self.X_test = self._scale(X_test)\n",
    "        \n",
    "        #https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n",
    "        self.y_train = y_train.values.ravel()\n",
    "\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        self.desc=desc\n",
    "\n",
    "        self.clf_model = MLPClassifier(solver=self.solver,\n",
    "                                       alpha=alpha, \n",
    "                                       hidden_layer_sizes=hidden_layer_sizes, \n",
    "                                       random_state=42, \n",
    "                                       max_iter=max_iter)   \n",
    "    \n",
    "    def print_self(self):\n",
    "        print(\"**\", \"Red Neuronal - \" + self.tipo, \"**\")\n",
    "        print(\"**\", \n",
    "              \"alpha=\" + str(self.alpha), \n",
    "              \"hidden_layer_sizes=\" + str(self.hidden_layer_sizes), \n",
    "              \"max_iter=\" + str(self.max_iter), \n",
    "              \"**\")\n",
    "\n",
    "    def _scale(self, X):\n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        return scaler.transform(X)\n",
    "\n",
    "\n",
    "class LBFGSNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'lbfgs'\n",
    "    tipo = \"LBFGS\"\n",
    "\n",
    "class SGDNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'sgd'\n",
    "    tipo = \"SGD\"\n",
    "\n",
    "class AdamNeuralNetwork(AbstractNeuralNetwork):\n",
    "    solver = 'adam'\n",
    "    tipo = 'ADAM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparator:\n",
    "    models = []\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def show_confusion_matrix(self):\n",
    "        for model in self.models:\n",
    "            model.show_confusion_matrix()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def show_classification_report(self):\n",
    "        for model in self.models:\n",
    "            model.show_classification_report()\n",
    "            print(\"\\n\")\n",
    "\n",
    "    def accuracy(self):\n",
    "        for model in self.models:\n",
    "            print(\"accuracy[{}]: {}\".format(model.tipo, model.accuracy()))\n",
    "    \n",
    "    def recall(self):\n",
    "        for model in self.models:\n",
    "            print(\"recall[{}]: {}\".format(model.tipo, model.recall()))\n",
    "    \n",
    "    def precision_score(self):\n",
    "        for model in self.models:\n",
    "            print(\"precision_score[{}]: {}\".format(model.tipo, model.precision_score()))\n",
    "            \n",
    "    def f1_score(self):\n",
    "        for model in self.models:\n",
    "            print(\"f1_score[{}-{}]: {}\".format(model.tipo, model.desc, model.f1_score()))\n",
    "    \n",
    "    def auc(self):\n",
    "        for model in self.models:\n",
    "            print(\"auc[{}-{}]: {}\".format(model.tipo, model.desc,model.auc()))\n",
    "            \n",
    "    def roc_curve(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        for model in self.models:\n",
    "            fpr, tpr, thresholds = roc_curve(model.y_test, model.y_predict, pos_label=1)\n",
    "            auc = metrics.roc_auc_score(model.y_test, model.y_predict)\n",
    "            #ax.plot(fpr, tpr)\n",
    "            ax.plot(fpr,tpr,label=\"[\"+model.tipo+ \"-\" + model.desc+\"] - AUC=\"+str(auc))\n",
    "            plt.title(f'Curva ROC')\n",
    "            ax.set_xlabel('False positive rate')\n",
    "            ax.set_ylabel('True positive rate')\n",
    "        ax.plot([0, 1], [0, 1], color='navy', linestyle='--', label='random')\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterTuning():\n",
    "    \n",
    "    def __init__(self, decisionTreeCriterion, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_train = y_train\n",
    "        self.decisionTreeCriterion = decisionTreeCriterion\n",
    "        \n",
    "    def train(self, parameters_to_tune_array, parameter_name):\n",
    "        def get_dec_tree_class(random_state=42, max_depth=None, min_samples_leaf=1, max_features=None, max_leaf_nodes=None, min_samples_split=2, min_weight_fraction_leaf=0):\n",
    "            return DecisionTreeClassifier(criterion=self.decisionTreeCriterion, \n",
    "                                        random_state=random_state,\n",
    "                                        max_depth=max_depth,\n",
    "                                        min_samples_leaf=min_samples_leaf,\n",
    "                                        max_features=max_features,\n",
    "                                        max_leaf_nodes=max_leaf_nodes,\n",
    "                                        min_samples_split=min_samples_split,\n",
    "                                        class_weight=None,\n",
    "                                        min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                                        splitter='best')\n",
    "            \n",
    "        print(\"parameters tuning for {}:{}\".format(parameter_name, parameters_to_tune_array))\n",
    "        train_results = []\n",
    "        test_results = []\n",
    "        max_depth=None\n",
    "        min_samples_split=2\n",
    "        min_samples_leaf=None\n",
    "        for curr_parameter in parameters_to_tune_array:\n",
    "            if parameter_name == 'max_depth':\n",
    "                max_depth = curr_parameter\n",
    "            elif parameter_name == 'min_samples_split':\n",
    "                min_samples_split = curr_parameter\n",
    "            elif parameter_name == 'min_samples_leaf':\n",
    "                min_samples_leaf = curr_parameter\n",
    "                \n",
    "            dt = get_dec_tree_class(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "            dt.fit(self.X_train, self.y_train)\n",
    "            train_pred = dt.predict(self.X_train)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_train, train_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous train results\n",
    "            train_results.append(roc_auc)\n",
    "            \n",
    "            y_pred = dt.predict(self.X_test)\n",
    "            false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_test, y_pred)\n",
    "            roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "            # Add auc score to previous test results\n",
    "            test_results.append(roc_auc)\n",
    "            \n",
    "        line1, = plt.plot(parameters_to_tune_array, train_results, 'b', label='Train AUC')\n",
    "        line2, = plt.plot(parameters_to_tune_array, test_results, 'r', label='Test AUC')\n",
    "        plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "        plt.ylabel('AUC score')\n",
    "        plt.xlabel(parameter_name)\n",
    "        plt.show()\n",
    "        \n",
    "        #TODO: Revisar si esto tiene sentido!!\n",
    "        ret = list(zip(list(map(lambda x, y: abs(x-y), test_results, train_results)), test_results, parameters_to_tune_array))\n",
    "        #Ordeno de mayor a menor los resultados de auc para test\n",
    "        ret.sort(key=lambda x: (-x[1]) )\n",
    "        #Ordeno de menor a mayor la diferencia de auc entre train y test\n",
    "        ret.sort(key=lambda x: (x[0]) )\n",
    "        print(\"Mejores parámetros para '{}': {}\".format(parameter_name,list(map(lambda x: x[2], ret))))\n",
    "        return ret\n",
    "    \n",
    "    def get_best_max_depth(self, hasta):\n",
    "        inicio = time.time()\n",
    "        max_depths = np.linspace(1, hasta, int(hasta/2), dtype=\"int\", endpoint=True)\n",
    "        best_values = self.train(max_depths, 'max_depth')\n",
    "        fin = time.time()\n",
    "        print(\"Tiempo total (min): {}\".format(round((fin-inicio)/60, 2)))\n",
    "        return best_values\n",
    "        \n",
    "    def get_best_min_samples_split(self, hasta=1.0):\n",
    "        inicio = time.time()\n",
    "        if hasta == 1.0:\n",
    "            min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "        else:\n",
    "            min_samples_splits = np.linspace(2, hasta, int(hasta/2), dtype=\"int\", endpoint=True)\n",
    "        best_values = self.train(min_samples_splits, 'min_samples_split')\n",
    "        fin = time.time()\n",
    "        print(\"Tiempo total (min): {}\".format(round((fin-inicio)/60, 2)))\n",
    "        return best_values\n",
    "    \n",
    "    def get_best_min_samples_leaf(self, hasta=1.0):\n",
    "        inicio = time.time()\n",
    "        if hasta == 1.0:\n",
    "            min_samples_leafs = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "        else:\n",
    "            min_samples_leafs = np.linspace(1, hasta, int(hasta/2), dtype=\"int\", endpoint=True)\n",
    "        best_values = self.train(min_samples_leafs, 'min_samples_leaf')\n",
    "        fin = time.time()\n",
    "        print(\"Tiempo total (min): {}\".format(round((fin-inicio)/60, 2)))\n",
    "        return best_values\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def list_only_parameters(l):\n",
    "        return [t[2] for t in l]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_best_result(ret1, ret2):#ret example [(abs(trai-test), auc_test, max_depth)]\n",
    "        avg1 = reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]), ret1)\n",
    "        avg1 = avg1[1]/len(ret1)\n",
    "        avg2 = reduce(lambda x,y: (x[0]+y[0],x[1]+y[1]), ret2)\n",
    "        avg2 = avg2[1]/len(ret2)\n",
    "        ret = ret1 if avg1 > avg2 else ret2\n",
    "        return ParameterTuning.list_only_parameters(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANALISIS DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levantamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Fraud.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadisticas descriptivas de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se borran las columnas 'nameOrig' y 'nameDest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Revisamos si hay valores perdidos (None, NaN) en el resto del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos contra la variable 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()[\"isFraud\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlacion de los datos entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de fraudes y no fraudes que hay en el dataset (Normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFraud\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de tipos de transacciones que hay en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transacciones fraudulentas y no fraudulentas diferenciadas por su tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.countplot(x=\"type\", data=df, hue=\"isFraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porcentajes de transacciones fraudulentas de cada tipo de transaccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "df_type_fraud = pd.DataFrame(dict(Counter(df['type'])).items(), columns=['type', 'IsFraud'])\n",
    "\n",
    "pie_porcentaje_transacciones_fraudulentas = px.pie(df_type_fraud, values=\"IsFraud\", names='type', title='Transacciones Fraudulentas', color_discrete_sequence=px.colors.sequential.RdBu)\n",
    "pie_porcentaje_transacciones_fraudulentas.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeo el type a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping_type = {'CASH_IN': 0,'CASH_OUT': 1,'PAYMENT': 2,'TRANSFER': 3,'DEBIT': 4}\n",
    "df['type_numeric'] = df.type.map(mapping_type)\n",
    "df.drop('type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('isFraud',axis=1)\n",
    "y = df[['isFraud']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Primeras pruebas con datos desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Separación de los datos de entrenamiento (80%) y datos para testing (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entreno el Arbol de Decision (Gini Impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline = GiniDecisionTree(dataset=df,\n",
    "                          X=X,\n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'])\n",
    "dtGini_baseline.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Medidas de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtGini_baseline.f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_baseline.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtGini_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Entreno el Arbol de Decision (Information Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline = InformationGainDecisionTree(dataset=df,\n",
    "                                                  X=X,\n",
    "                                                  X_train=X_train, \n",
    "                                                  X_test=X_test, \n",
    "                                                  y_train=y_train,\n",
    "                                                  y_test=y_test, \n",
    "                                                  target=df['isFraud'])\n",
    "dtInfoGain_baseline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hice una prueba agregando \"dummies\" en lugar de fijar un número para cada valor de \"type\"\n",
    "df2 = pd.read_csv(\"./Fraud.csv\")\n",
    "df2.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n",
    "\n",
    "#Getting Dummies from all other categorical vars\n",
    "for col in df2.dtypes[df2.dtypes == 'object'].index:\n",
    "    for_dummy = df2.pop(col)\n",
    "    df2 = pd.concat([df2, pd.get_dummies(for_dummy, prefix=col)], axis=1)\n",
    "X2 = df2.drop('isFraud',axis=1)\n",
    "y2 = df2[['isFraud']]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "dtInfoGain2 = InformationGainDecisionTree(df2, X=X2, \n",
    "                                        X_train=X2_train, \n",
    "                                        X_test=X2_test, \n",
    "                                        y_train=y2_train, \n",
    "                                        y_test=y2_test, \n",
    "                                        target=df2['isFraud'])\n",
    "dtInfoGain2.train()\n",
    "dtInfoGain2.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtInfoGain2.auc())\n",
    "dtGini_baseline.auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Impresion del Arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtInfoGain_baseline.show_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area Under Curve) como métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain_baseline.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparo parámetros para max_depth, min_samples_split y min_samples_leaf (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "infogain_best_max_depth_baseline = parameterTuning_InfoGain.get_best_max_depth(30)\n",
    "infogain_best_max_depth_baseline = list_only_n_comp(infogain_best_max_depth_baseline, 2)\n",
    "infogain_best_min_samples_split_baseline_1 = parameterTuning_InfoGain.get_best_min_samples_split()\n",
    "infogain_best_min_samples_split_baseline_2 = parameterTuning_InfoGain.get_best_min_samples_split(20)\n",
    "infogain_best_min_samples_split_baseline = get_best_result(infogain_best_min_samples_split_baseline_1, infogain_best_min_samples_split_baseline_2)\n",
    "infogain_best_min_samples_leaf_baseline_1 = parameterTuning_InfoGain.get_best_min_samples_leaf()\n",
    "infogain_best_min_samples_leaf_baseline_2 = parameterTuning_InfoGain.get_best_min_samples_leaf(20)\n",
    "infogain_best_min_samples_leaf_baseline = get_best_result(infogain_best_min_samples_leaf_baseline_1, infogain_best_min_samples_leaf_baseline_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameterTuning_Gini = ParameterTuning(decisionTreeCriterion=\"gini\",\n",
    "                                            X_train=X_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_train,\n",
    "                                            y_test=y_test)\n",
    "gini_best_max_depth_baseline = parameterTuning_Gini.get_best_max_depth(30)\n",
    "gini_best_max_depth_baseline = list_only_n_comp(gini_best_max_depth_baseline,2)\n",
    "gini_best_min_samples_split_baseline_1 = parameterTuning_Gini.get_best_min_samples_split()\n",
    "gini_best_min_samples_split_baseline_2 = parameterTuning_Gini.get_best_min_samples_split(20)\n",
    "gini_best_min_samples_split_baseline = get_best_result(gini_best_min_samples_split_baseline_1, gini_best_min_samples_split_baseline_2)\n",
    "gini_best_min_samples_leaf_baseline_1 = parameterTuning_Gini.get_best_min_samples_leaf()\n",
    "gini_best_min_samples_leaf_baseline_2 = parameterTuning_Gini.get_best_min_samples_leaf(20)\n",
    "gini_best_min_samples_leaf_baseline = get_best_result(gini_best_min_samples_leaf_baseline_1, gini_best_min_samples_leaf_baseline_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pruebas con datos Balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes and plot\n",
    "target_count = df[\"isFraud\"].value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "target_count.plot(kind='bar', title='Count (isFraud)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "target_0_count, target_1_count=df[\"isFraud\"].value_counts()\n",
    "# Seperate classes\n",
    "target_0 = df[df[\"isFraud\"] == 0]\n",
    "target_1 = df[df[\"isFraud\"] == 1]\n",
    "\n",
    "# Resample target1 to match target 0 count\n",
    "target_0_undersample = target_0.sample(target_1_count)\n",
    "# Merge back to single df\n",
    "test_undersample = pd.concat([target_0_undersample, target_1], axis=0)\n",
    "# Show counts and plot\n",
    "print('Random under-sampling:')\n",
    "test_undersample[\"isFraud\"].value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersample = test_undersample.drop('isFraud',axis=1)\n",
    "y_undersample = test_undersample[['isFraud']]\n",
    "X_undersample_train, X_undersample_test, y_undersample_train, y_undersample_test = train_test_split(X_undersample, y_undersample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_undersample_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_undersample = GiniDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'])\n",
    "dtGini_undersample.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_undersample.show_classification_report()\n",
    "dtGini_undersample.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "target_0_count, target_1_count = df[\"isFraud\"].value_counts()\n",
    "# Seperate classes\n",
    "target_0 = df[df[\"isFraud\"] == 0]\n",
    "target_1 = df[df[\"isFraud\"] == 1]\n",
    "\n",
    "# Resample target0 to match target 1 count\n",
    "target_1_oversample = target_1.sample(target_0_count, replace=True)\n",
    "# Merge back to single df\n",
    "test_oversample = pd.concat([target_1_oversample, target_0], axis=0)\n",
    "# Show counts and plot\n",
    "print('Random over-sampling:')\n",
    "print(test_oversample[\"isFraud\"].value_counts())\n",
    "test_oversample[\"isFraud\"].value_counts().plot(kind='bar', title='Count (isFraud)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversample = test_oversample.drop('isFraud',axis=1)\n",
    "y_oversample = test_oversample[['isFraud']]\n",
    "X_oversample_train, X_oversample_test, y_oversample_train, y_oversample_test = train_test_split(X_oversample, y_oversample, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_oversample = GiniDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'])\n",
    "dtGini_oversample.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_oversample.show_classification_report()\n",
    "dtGini_oversample.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote = GiniDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_smote_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_smote_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'])\n",
    "dtGini_smote.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote.show_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote.precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini_smote.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparo parámetros para datos Balanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain_undersample = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_undersample_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_undersample_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "infogain_best_max_depth_undersample = parameterTuning_InfoGain_undersample.get_best_max_depth(30)\n",
    "infogain_best_max_depth_undersample = ParameterTuning.list_only_parameters(infogain_best_max_depth_undersample)\n",
    "\n",
    "infogain_best_min_samples_split_undersample_1 = parameterTuning_InfoGain_undersample.get_best_min_samples_split()\n",
    "infogain_best_min_samples_split_undersample_2 = parameterTuning_InfoGain_undersample.get_best_min_samples_split(20)\n",
    "infogain_best_min_samples_split_undersample = ParameterTuning.get_best_result(infogain_best_min_samples_split_undersample_1, infogain_best_min_samples_split_undersample_2)\n",
    "\n",
    "infogain_best_min_samples_leaf_undersample_1 = parameterTuning_InfoGain_undersample.get_best_min_samples_leaf()\n",
    "infogain_best_min_samples_leaf_undersample_2 = parameterTuning_InfoGain_undersample.get_best_min_samples_leaf(20)\n",
    "infogain_best_min_samples_leaf_undersample = ParameterTuning.get_best_result(infogain_best_min_samples_leaf_undersample_1, infogain_best_min_samples_leaf_undersample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_Gini_undersample = ParameterTuning(decisionTreeCriterion=\"gini\",\n",
    "                                            X_train=X_undersample_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_undersample_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "gini_best_max_depth_undersample = parameterTuning_Gini_undersample.get_best_max_depth(30)\n",
    "gini_best_max_depth_undersample = ParameterTuning.list_only_parameters(gini_best_max_depth_undersample)\n",
    "\n",
    "gini_best_min_samples_split_undersample_1 = parameterTuning_Gini_undersample.get_best_min_samples_split()\n",
    "gini_best_min_samples_split_undersample_2 = parameterTuning_Gini_undersample.get_best_min_samples_split(20)\n",
    "gini_best_min_samples_split_undersample = ParameterTuning.get_best_result(gini_best_min_samples_split_undersample_1, gini_best_min_samples_split_undersample_2)\n",
    "\n",
    "gini_best_min_samples_leaf_undersample_1 = parameterTuning_Gini_undersample.get_best_min_samples_leaf()\n",
    "gini_best_min_samples_leaf_undersample_2 = parameterTuning_Gini_undersample.get_best_min_samples_leaf(20)\n",
    "gini_best_min_samples_leaf_undersample = ParameterTuning.get_best_result(gini_best_min_samples_leaf_undersample_1, gini_best_min_samples_leaf_undersample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain_over = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_oversample_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_oversample_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "infogain_best_max_depth_oversample = parameterTuning_InfoGain_over.get_best_max_depth(30)\n",
    "infogain_best_max_depth_oversample = ParameterTuning.list_only_parameters(best_max_depth_oversample)\n",
    "\n",
    "infogain_best_min_samples_split_oversample_1 = parameterTuning_InfoGain_over.get_best_min_samples_split()\n",
    "infogain_best_min_samples_split_oversample_2 = parameterTuning_InfoGain_over.get_best_min_samples_split(20)\n",
    "infogain_best_min_samples_split_oversample = ParameterTuning.get_best_result(best_min_samples_split_oversample_1, best_min_samples_split_oversample_2)\n",
    "\n",
    "infogain_best_min_samples_leaf_oversample_1 = parameterTuning_InfoGain_over.get_best_min_samples_leaf()\n",
    "infogain_best_min_samples_leaf_oversample_2 = parameterTuning_InfoGain_over.get_best_min_samples_leaf(20)\n",
    "infogain_best_min_samples_leaf_oversample = ParameterTuning.get_best_result(best_min_samples_leaf_oversample_1, best_min_samples_leaf_oversample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_Gini_oversample = ParameterTuning(decisionTreeCriterion=\"gini\",\n",
    "                                            X_train=X_oversample_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_oversample_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "gini_best_max_depth_oversample = parameterTuning_Gini_oversample.get_best_max_depth(30)\n",
    "gini_best_max_depth_oversample = ParameterTuning.list_only_parameters(best_max_depth_oversample)\n",
    "\n",
    "gini_best_min_samples_split_oversample_1 = parameterTuning_Gini_oversample.get_best_min_samples_split()\n",
    "gini_best_min_samples_split_oversample_2 = parameterTuning_Gini_oversample.get_best_min_samples_split(20)\n",
    "gini_best_min_samples_split_oversample = ParameterTuning.get_best_result(best_min_samples_split_oversample_1, best_min_samples_split_oversample_2)\n",
    "\n",
    "gini_best_min_samples_leaf_oversample_1 = parameterTuning_Gini_oversample.get_best_min_samples_leaf()\n",
    "gini_best_min_samples_leaf_oversample_2 = parameterTuning_Gini_oversample.get_best_min_samples_leaf(20)\n",
    "gini_best_min_samples_leaf_oversample = ParameterTuning.get_best_result(best_min_samples_leaf_oversample_1, best_min_samples_leaf_oversample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_InfoGain_smote = ParameterTuning(decisionTreeCriterion=\"entropy\",\n",
    "                                            X_train=X_smote_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_smote_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "infogain_best_max_depth_smote = parameterTuning_InfoGain_smote.get_best_max_depth(30)\n",
    "infogain_best_max_depth_smote = ParameterTuning.list_only_parameters(best_max_depth_smote)\n",
    "\n",
    "infogain_best_min_samples_split_smote_1 = parameterTuning_InfoGain_smote.get_best_min_samples_split()\n",
    "infogain_best_min_samples_split_smote_2 = parameterTuning_InfoGain_smote.get_best_min_samples_split(20)\n",
    "infogain_best_min_samples_split_smote = ParameterTuning.get_best_result(best_min_samples_split_smote_1, best_min_samples_split_smote_2)\n",
    "\n",
    "infogain_best_min_samples_leaf_smote_1 = parameterTuning_InfoGain_smote.get_best_min_samples_leaf()\n",
    "infogain_best_min_samples_leaf_smote_2 = parameterTuning_InfoGain_smote.get_best_min_samples_leaf(20)\n",
    "infogain_best_min_samples_leaf_smote = ParameterTuning.get_best_result(best_min_samples_leaf_smote_1, best_min_samples_leaf_smote_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterTuning_Gini_smote = ParameterTuning(decisionTreeCriterion=\"gini\",\n",
    "                                            X_train=X_smote_train,\n",
    "                                            X_test=X_test,\n",
    "                                            y_train=y_smote_train,\n",
    "                                            y_test=y_test)\n",
    "\n",
    "gini_best_max_depth_smote = parameterTuning_Gini_smote.get_best_max_depth(30)\n",
    "gini_best_max_depth_smote = ParameterTuning.list_only_parameters(best_max_depth_smote)\n",
    "\n",
    "gini_best_min_samples_split_smote_1 = parameterTuning_Gini_smote.get_best_min_samples_split()\n",
    "gini_best_min_samples_split_smote_2 = parameterTuning_Gini_smote.get_best_min_samples_split(20)\n",
    "gini_best_min_samples_split_smote = ParameterTuning.get_best_result(best_min_samples_split_smote_1, best_min_samples_split_smote_2)\n",
    "\n",
    "gini_best_min_samples_leaf_smote_1 = parameterTuning_Gini_smote.get_best_min_samples_leaf()\n",
    "gini_best_min_samples_leaf_smote_2 = parameterTuning_Gini_smote.get_best_min_samples_leaf(20)\n",
    "gini_best_min_samples_leaf_smote = ParameterTuning.get_best_result(best_min_samples_leaf_smote_1, best_min_samples_leaf_smote_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV para DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary grid for grid search\n",
    "param_grid_baseline_gini = {'criterion': ['gini'],\n",
    "              'max_depth': gini_best_max_depth_baseline[:5],\n",
    "              'min_samples_split': gini_best_min_samples_split_baseline[:5],\n",
    "              'min_samples_leaf': gini_best_min_samples_leaf_baseline[:5]}\n",
    "\n",
    "param_grid_baseline_infogain = {'criterion': ['entropy'],\n",
    "              'max_depth': infogain_best_max_depth_baseline[:5],\n",
    "              'min_samples_split': infogain_best_min_samples_split_baseline[:5],\n",
    "              'min_samples_leaf': infogain_best_min_samples_leaf_baseline[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary grid for grid search\n",
    "param_grid_undersample_gini = {'criterion': ['gini'],\n",
    "              'max_depth': gini_best_max_depth_undersample[:5],\n",
    "              'min_samples_split': gini_best_min_samples_split_undersample[:5],\n",
    "              'min_samples_leaf': gini_best_min_samples_leaf_undersample[:5]}\n",
    "\n",
    "param_grid_undersample_infogain = {'criterion': ['entropy'],\n",
    "              'max_depth': infogain_best_max_depth_undersample[:5],\n",
    "              'min_samples_split': infogain_best_min_samples_split_undersample[:5],\n",
    "              'min_samples_leaf': infogain_best_min_samples_leaf_undersample[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary grid for grid search\n",
    "param_grid_oversample_gini = {'criterion': ['gini'],\n",
    "              'max_depth': gini_best_max_depth_oversample[:5],\n",
    "              'min_samples_split': gini_best_min_samples_split_oversample[:5],\n",
    "              'min_samples_leaf': gini_best_min_samples_leaf_oversample[:5]}\n",
    "\n",
    "param_grid_oversample_infogain = {'criterion': ['entropy'],\n",
    "              'max_depth': infogain_best_max_depth_oversample[:5],\n",
    "              'min_samples_split': infogain_best_min_samples_split_oversample[:5],\n",
    "              'min_samples_leaf': infogain_best_min_samples_leaf_oversample[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary grid for grid search\n",
    "param_grid_smote_gini = {'criterion': ['gini'],\n",
    "              'max_depth': gini_best_max_depth_smote[:5],\n",
    "              'min_samples_split': gini_best_min_samples_split_smote[:5],\n",
    "              'min_samples_leaf': gini_best_min_samples_leaf_smote[:5]}\n",
    "\n",
    "param_grid_smote_infogain = {'criterion': ['entropy'],\n",
    "              'max_depth': infogain_best_max_depth_smote[:5],\n",
    "              'min_samples_split': infogain_best_min_samples_split_smote[:5],\n",
    "              'min_samples_leaf': infogain_best_min_samples_leaf_smote[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainGridSearchDTC(param_grid, X_train, y_train):\n",
    "    #Fitting grid search to the train data with 3 folds\n",
    "    gridsearch_dt = GridSearchCV(estimator= DecisionTreeClassifier(), \n",
    "                          param_grid= param_grid,\n",
    "                          cv=3, \n",
    "                          n_jobs=-1, \n",
    "                          scoring='roc_auc', \n",
    "                          verbose=2)\n",
    "    inicio = time.time()\n",
    "    gridsearch_dt.fit(X_train, y_train)\n",
    "    fin = time.time()\n",
    "    print(\"Tiempo total (min): {}\".format((fin-inicio)/60))\n",
    "    return gridsearch_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_gini_baseline = TrainGridSearchDTC(param_grid_baseline_gini, X_train, y_train)\n",
    "print(gridsearch_gini_baseline.best_params_)\n",
    "print(gridsearch_gini_baseline.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_infogain_baseline = TrainGridSearchDTC(param_grid_baseline_infogain, X_train, y_train)\n",
    "print(gridsearch_infogain_baseline.best_params_)\n",
    "print(gridsearch_infogain_baseline.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_gini_undersample = TrainGridSearchDTC(param_grid_undersample_gini, X_undersample_train, y_undersample_train)\n",
    "print(\"Best params: \", gridsearch_gini_undersample.best_params_)\n",
    "print(\"score: \",gridsearch_gini_undersample.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_infogain_undersample = TrainGridSearchDTC(param_grid_undersample_infogain, X_undersample_train, y_undersample_train)\n",
    "print(gridsearch_infogain_undersample.best_params_)\n",
    "print(gridsearch_infogain_undersample.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_gini_oversample = TrainGridSearchDTC(param_grid_oversample_gini, X_oversample_train, y_oversample_train)\n",
    "print(gridsearch_gini_oversample.best_params_)\n",
    "print(gridsearch_gini_oversample.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_infogain_oversample = TrainGridSearchDTC(param_grid_oversample_infogain, X_oversample_train, y_oversample_train)\n",
    "print(gridsearch_infogain_oversample.best_params_)\n",
    "print(gridsearch_infogain_oversample.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_gini_smote = TrainGridSearchDTC(param_grid_smote_gini, X_smote_train, y_smote_train)\n",
    "print(gridsearch_gini_smote.best_params_)\n",
    "print(gridsearch_gini_smote.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_infogain_smote = TrainGridSearchDTC(param_grid_smote_infogain, X_smote_train, y_smote_train)\n",
    "print(gridsearch_infogain_smote.best_params_)\n",
    "print(gridsearch_infogain_smote.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparador de modelos DT (Gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtGini = GiniDecisionTree(df,\n",
    "                          X=X, \n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'],\n",
    "                          desc=\"desbalanceado\")\n",
    "dtGini.train()\n",
    "\n",
    "dtGini_bestparams = GiniDecisionTree(df,\n",
    "                          X=X, \n",
    "                          X_train=X_train, \n",
    "                          X_test=X_test, \n",
    "                          y_train=y_train, \n",
    "                          y_test=y_test, \n",
    "                          target=df['isFraud'],\n",
    "                          max_depth=gridsearch_gini_baseline.best_params_['max_depth'],\n",
    "                          min_samples_split=gridsearch_gini_baseline.best_params_['min_samples_split'],\n",
    "                          min_samples_leaf=gridsearch_gini_baseline.best_params_['min_samples_leaf'],\n",
    "                          desc=\"desbalanceado-bp\")\n",
    "dtGini_bestparams.train()\n",
    "\n",
    "dtGini_undersample = GiniDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'],\n",
    "                                      desc=\"undersample\")\n",
    "dtGini_undersample.train()\n",
    "\n",
    "dtGini_undersample_bestparams = GiniDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'],\n",
    "                                      max_depth=gridsearch_gini_undersample.best_params_['max_depth'],\n",
    "                                      min_samples_split=gridsearch_gini_undersample.best_params_['min_samples_split'],\n",
    "                                      min_samples_leaf=gridsearch_gini_undersample.best_params_['min_samples_leaf'],\n",
    "                                      desc=\"undersample-bp\")\n",
    "dtGini_undersample_bestparams.train()\n",
    "\n",
    "dtGini_oversample = GiniDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'],\n",
    "                                      desc=\"oversample\")\n",
    "dtGini_oversample.train()\n",
    "\n",
    "dtGini_oversample_bestparams = GiniDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'],\n",
    "                                      max_depth=gridsearch_gini_oversample.best_params_['max_depth'],\n",
    "                                      min_samples_split=gridsearch_gini_oversample.best_params_['min_samples_split'],\n",
    "                                      min_samples_leaf=gridsearch_gini_oversample.best_params_['min_samples_leaf'],\n",
    "                                      desc=\"oversample-bp\")\n",
    "dtGini_oversample_bestparams.train()\n",
    "\n",
    "dtGini_smote = GiniDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_smote_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_smote_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  desc=\"smote\")\n",
    "dtGini_smote.train()\n",
    "\n",
    "dtGini_smote_bestparams = GiniDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_smote_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_smote_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  max_depth=gridsearch_gini_smote.best_params_['max_depth'],\n",
    "                                  min_samples_split=gridsearch_gini_smote.best_params_['min_samples_split'],\n",
    "                                  min_samples_leaf=gridsearch_gini_smote.best_params_['min_samples_leaf'],\n",
    "                                  desc=\"smote-bp\")\n",
    "dtGini_smote_bestparams.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtGini, dtGini_bestparams, dtGini_undersample, dtGini_undersample_bestparams\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.auc()\n",
    "comparator.roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtGini_oversample, dtGini_oversample_bestparams,\n",
    "    dtGini_smote, dtGini_smote_bestparams\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.auc()\n",
    "comparator.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejor modelo para GINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparador de modelos DT (Information Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtInfoGain = InformationGainDecisionTree(df,\n",
    "                                         X=X, \n",
    "                                         X_train=X_train, \n",
    "                                         X_test=X_test, \n",
    "                                         y_train=y_train, \n",
    "                                         y_test=y_test, \n",
    "                                         target=df['isFraud'],\n",
    "                                         desc=\"desbalanceado\")\n",
    "dtInfoGain.train()\n",
    "\n",
    "dtInfoGain_undersample = InformationGainDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'],\n",
    "                                      desc=\"undersample\")\n",
    "dtInfoGain_undersample.train()\n",
    "\n",
    "dtInfoGain_undersample_bestparams = InformationGainDecisionTree(test_undersample,\n",
    "                                      X=X_undersample, \n",
    "                                      X_train=X_undersample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_undersample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_undersample['isFraud'],\n",
    "                                      max_depth=gridsearch_infogain_undersample.best_params_['max_depth'],\n",
    "                                      min_samples_split=gridsearch_infogain_undersample.best_params_['min_samples_split'],\n",
    "                                      min_samples_leaf=gridsearch_infogain_undersample.best_params_['min_samples_leaf'],\n",
    "                                      desc=\"undersample\")\n",
    "dtInfoGain_undersample_bestparams.train()\n",
    "\n",
    "dtInfoGain_oversample = InformationGainDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'],\n",
    "                                      desc=\"oversample\")\n",
    "dtInfoGain_oversample.train()\n",
    "\n",
    "dtInfoGain_oversample_bestparams = InformationGainDecisionTree(test_oversample,\n",
    "                                      X=X_oversample, \n",
    "                                      X_train=X_oversample_train, \n",
    "                                      X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                      y_train=y_oversample_train, \n",
    "                                      y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                      target=test_oversample['isFraud'],\n",
    "                                      max_depth=gridsearch_infogain_oversample.best_params_['max_depth'],\n",
    "                                      min_samples_split=gridsearch_infogain_oversample.best_params_['min_samples_split'],\n",
    "                                      min_samples_leaf=gridsearch_infogain_oversample.best_params_['min_samples_leaf'],\n",
    "                                      desc=\"oversample\")\n",
    "dtInfoGain_oversample_bestparams.train()\n",
    "\n",
    "dtInfoGain_smote = InformationGainDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_smote_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_smote_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  desc=\"smote\")\n",
    "dtInfoGain_smote.train()\n",
    "\n",
    "dtInfoGain_smote_bestparams = InformationGainDecisionTree(df,\n",
    "                                  X=X, \n",
    "                                  X_train=X_smote_train, \n",
    "                                  X_test=X_test, # Para testear debe ser sobre el dataset original\n",
    "                                  y_train=y_smote_train, \n",
    "                                  y_test=y_test, # Para testear debe ser sobre el dataset original\n",
    "                                  target=df['isFraud'],\n",
    "                                  max_depth=gridsearch_infogain_smote.best_params_['max_depth'],\n",
    "                                  min_samples_split=gridsearch_infogain_smote.best_params_['min_samples_split'],\n",
    "                                  min_samples_leaf=gridsearch_infogain_smote.best_params_['min_samples_leaf'],\n",
    "                                  desc=\"smote\")\n",
    "dtInfoGain_smote_bestparams.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtInfoGain, dtInfoGain_undersample, \n",
    "    dtInfoGain_bestparams, dtInfoGain_undersample_bestparams\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.auc()\n",
    "comparator.roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    dtInfoGain_oversample, dtInfoGain_smote,\n",
    "    dtInfoGain_oversample_bestparams, dtInfoGain_smote_bestparams\n",
    "]\n",
    "\n",
    "comparator = Comparator(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.auc()\n",
    "comparator.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejor modelo para Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entreno Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.show_classification_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.recall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.precision_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV para NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,10,10), (10,20,10), (20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= mlp, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=2, \n",
    "                          n_jobs=-1,  \n",
    "                          verbose=2,\n",
    "                          scoring=\"roc_auc\")\n",
    "\n",
    "inicio = time.time()\n",
    "gridsearch.fit(X_train, y_train.to_numpy().ravel())\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tiempo total (min): {}\".format((fin-inicio)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparador modelos NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = LBFGSNeuralNetwork(X=X,\n",
    "                        y=y,\n",
    "                        X_train=X_train, \n",
    "                        X_test=X_test, \n",
    "                        y_train=y_train, \n",
    "                        y_test=y_test, \n",
    "                        alpha=1e-5, \n",
    "                        hidden_layer_sizes=(15,), \n",
    "                        max_iter=200)\n",
    "\n",
    "nn.train()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
